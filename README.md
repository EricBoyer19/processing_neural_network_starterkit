processing_neural_network_starterkit
Transposed to processing through java of the good material from matt mazur.
https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/

Here we just took:
-relu activation function instead of the sigmoid, for obvious reasons, you will find over internet.
-We also take care the derivative of the error in respect with the bias weights that influence also the total cost.

I know the code is not optimzed, and I should use matrix calculation approch to get rid of all this mess of floats I use as in quick an dirty step, focusing on "is it good enough to do the job"?

Be kind enough, I'm working on a much more optimized version, which should not take long. 
A matter of time and interest.
By the way thanks to Daniel Shiffman, who shares a lot through the coding train channel, 
with a great spirit of sharing live his approach in limited time coding stuff.

I suggest you also go and see what's on the subject describe in youtube channel 3brown1blue,
https://www.youtube.com/watch?v=tIeHLnjs5U8
which explains very clearly all the stuff you need, to build your first neural network, starting from nowhere.
Hope this material will help newbees.

Anyway, the aim here is to propose a starting kit which is not perfect and from nothing, sharing what i understood from others i do thanks for it. Have fun, and make of this material a better thing for the community, share it and propose enhanced versions.
