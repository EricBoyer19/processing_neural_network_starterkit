processing_neural_network_starterkit

Transposed to processing through java of the good material from matt mazur.
https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/

Here we just took:
-relu activation function instead of the sigmoid, for obvious reasons, you will find over internet.
-We also take care the derivative of the error in respect with the bias weights that influence also the total cost.

I know the code is not optimzed, and I should use matrix calculation approch,
to get rid of all this mess of floats that I use as in a quick and dirty step, 
focusing on "is it good enough to do the job"?

Be kind enough, I'm working on a much more optimized version. 
A matter of time (as usual).
By the way thanks to Daniel Shiffman, who shares a lot daily through the coding train channel,
with such a passion that I share.
https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw

I suggest you also go and see what's on the subject describe in youtube channel 3brown1blue,
https://www.youtube.com/watch?v=tIeHLnjs5U8
which explains very clearly all the stuff you need, to build your first neural network, starting from nowhere.
Hope this material will help newbees.

Anyway, the aim here is to propose a starting kit which is not perfect and from nothing, 
sharing what i understood from others i do thanks for it. 

Have fun, and make it a better material for the community, share and propose enhanced versions.
all a matter of spirit I believe.

cheers.
